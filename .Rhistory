plot(a, type="l", col = c('#663300'), lwd =2 ,xlab = "Iterations", ylab = "Mean value", main = expression("Cumulative Emperical Mean " (lambda *" = 0.2")))
abline(h=theo_mean, col = c('#FF6666'))
abline(h=theo_mean, col = c('#FF6666'), lwd=1)
abline(h=theo_mean, col = c('#FF6666'), lwd=2)
mean <- mean(exp_distrib)
print(mean)
mean(exp_distrib)
print(sample_mean)
hist(mean,col = "blue")
abline(v = sample_mean, col = c('#FF6666'))
summary(mean)
a <-cumsum(colmean)/seq_along(colmean)
plot(a, type="l", col = c('#663300'), lwd =2 ,xlab = "Iterations", ylab = "Mean value", main = expression("Cumulative Emperical Mean " (lambda *" = 0.2")))
abline(h=theo_mean, col = c('#FF6666'), lwd=2)
cumul_mean <-cumsum(colmean)/seq_along(colmean)
plot(cumul_mean, type="l", col = c('#663300'), lwd =2 ,xlab = "Iterations", ylab = "Mean value", main = expression("Cumulative Emperical Mean " (lambda *" = 0.2")))
abline(h=theo_mean, col = c('#FF6666'), lwd=2)
mean(exp_distrib)
car(exp_distrib)
var(exp_distrib)
sd(exp_distrib)
theo_var <- 1/((lambda^2)*n)
theo_var <- theo_mean^2
theo_var <- theo_mean / n
theo_var <- 1/(lambda^2)
var(exp_distrib)
sample_mean <- mean(colmean)
sample_var <- var(colmean)
mean(exp_distrib)
var(exp_distrib)
theo_var <- 1/(lambda^2/n)
theo_var <- 1/(lambda^2)/n
mean(exp_distrib)
var(exp_distrib)
exp_distrib2 <- replicate(iteration,rexp(n, lambda))
dim (exp_distrib2)
hist(exp_distrib2, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17), xlim = c(0,40))
lines(density(exp_distrib2), col = c('#FF6666'), lwd=3)
colmean <- colMeans(exp_distrib2)
sample_mean <- mean(colmean)
exp_distrib <- rexp(n, lambda)
mean(exp_distrib)
ncol(exp_distrib)
nrow(exp_distrib)
length(exp_distrib)
head(exp_distrib)
print(paste("Theorical mean: ", theo_mean))
print(paste("Theorical mean equal to ", theo_mean))
print(paste("Theorical mean equal to", theo_mean))
print(paste("Theorical mean equal to", theo_mean), "ada")
print(paste("Theorical mean equal to", theo_mean, "and"))
print(paste("Theorical mean equal to", theo_mean, "and sample mean equal to",sample_mean))
print(paste("Theorical mean equal to", theo_mean, "and sample mean equal to",round(sample_mean,2))
# Draw the cumulative empirical mean
cumul_mean <-cumsum(colmean)/seq_along(colmean)
plot(cumul_mean, type="l", col = c('#663300'), lwd =2 ,xlab = "Iterations", ylab = "Mean value", main = expression("Cumulative Emperical Mean " (lambda *" = 0.2")))
abline(h=theo_mean, col = c('#FF6666'), lwd=2)
print(paste("Theorical mean equal to", theo_mean, "and sample mean equal to",round(sample_mean,2))
# Draw the cumulative empirical mean
cumul_mean <-cumsum(colmean)/seq_along(colmean)
plot(cumul_mean, type="l", col = c('#663300'), lwd =2 ,xlab = "Iterations", ylab = "Mean value", main = expression("Cumulative Emperical Mean " (lambda *" = 0.2")))
abline(h=theo_mean, col = c('#FF6666'), lwd=2)
print(paste("Theorical mean equal to", theo_mean, "and sample mean equal to",round(sample_mean,2))
# Draw the cumulative empirical mean
cumul_mean <-cumsum(colmean)/seq_along(colmean)
plot(cumul_mean, type="l", col = c('#663300'), lwd =2 ,xlab = "Iterations", ylab = "Mean value", main = expression("Cumulative Emperical Mean " (lambda *" = 0.2")))
abline(h=theo_mean, col = c('#FF6666'), lwd=2)
print(paste("Theorical mean equal to", theo_mean, "and sample mean equal to",round(sample_mean,2)))
print(paste("Theorical mean equal to", theo_mean, "and sample mean equal to",round(sample_mean,3)))
print(paste("Theorical mean equal to", theo_mean, "and sample mean equal to",round(sample_mean,2)))
print(paste("Theorical variance equal to", theo_var, "and sample variance equal to",round(sample_var,2)))
print(paste("Theorical mean equal to", theo_mean, "and sample mean equal to",round(sample_mean,2)))
print(paste("Theorical variance equal to", theo_var, "and sample variance equal to",round(sample_var,3)))
cumum_var <- cumsum(var(colmean))/seq_along(colmean)
cumum_var <- cumsum(var(colmean))
hist(colmean)
hist(colmean, breaks = 10)
hist(colmean, breaks = 30)
hist(colmean, breaks = 25)
hist(colmean, breaks = 10)
hist(colmean, breaks = 50)
hist(colmean, breaks = 50, freq = FALSE)
hist(colmean, breaks = 20, freq = FALSE)
hist(colmean, breaks = 20, freq = FALSE, xlim = c(0,10))
hist(colmean, breaks = 20, freq = FALSE, xlim = c(1,9))
hist(colmean, breaks = 20, freq = FALSE, xlim = c(1,9))
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9))
lines(density(colmean))
lines(density(colmean, bw=1))
lines(density(colmean, bw=2))
lines(density(colmean, bw=0.2))
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9))
lines(density(colmean, bw=0.2))
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9))
lines(density(colmean))
curve(dnorm(colmean))
curve(dnorm(colmean),xlim=c(2,9))
dnorm(colmean)
hist(dnorm(colmean))
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9))
lines(density(colmean))
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9),col = c('#99CCFF'))
lines(density(colmean), col = c('#FF6666'), lwd=3)
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9), ylim = c(0,0.7),col = c('#99CCFF'))
lines(density(colmean), col = c('#FF6666'), lwd=3)
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9), ylim = c(0,0.6),col = c('#99CCFF'))
lines(density(colmean), col = c('#FF6666'), lwd=3)
ablines(v=sample_mean, col = c('#66CC99'), lwd=3)
abline(v=sample_mean, col = c('#66CC99'), lwd=3)
abline(v=sample_mean, col = c('#FFFF66'), lwd=3)
abline(v=sample_mean, col = c('#FF66CC'), lwd=3)
FFFF66
hist(exp_distrib2, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17), xlim = c(0,40))
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9), ylim = c(0,0.6),col = c('#99CCFF'))
lines(density(colmean), col = c('#FF6666'), lwd=3)
abline(v=sample_mean, col = c('#66CC99'), lwd=3)
abline(v=sample_mean, col = c('#FFFF66'), lwd=3)
abline(v=sample_mean, col = c('#FFFF33'), lwd=3)
legend("topright", legend = c("Mean"))
legend("topright", legend = c("Mean"), col = c('#FFFF33'))
legend("topright", legend = c("Mean"), col = c('#FFFF33'))
legend("topright", legend = c("Mean"), col = c('#FF6666'))
legend("topright", legend = c("Mean"), col = c('#FFFF33'), lwd =2)
abline(v=sample_mean, col = c('#FF66FF'), lwd=3)
legend("topright", legend = c("Mean"), col = c('#FF66FF'), lwd =2)
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9), ylim = c(0,0.6),col = c('#99CCFF'), main = "Mean distribution", xlab = "Mean")
lines(density(colmean), col = c('#FF6666'), lwd=3)
abline(v=sample_mean, col = c('#FF66FF'), lwd=3)
legend("topright", legend = c("Mean"), col = c('#FF66FF'), lwd =2)
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9), ylim = c(0,0.6),col = c('#99CCFF'), main = "Mean distribution : almost Normal", xlab = "Mean")
lines(density(colmean), col = c('#FF6666'), lwd=3)
abline(v=sample_mean, col = c('#FF66FF'), lwd=3)
legend("topright", legend = c("Mean"), col = c('#FF66FF'), lwd =2)
hist(exp_distrib2, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17), xlim = c(0,40))
lines(density(exp_distrib2), col = c('#FF6666'), lwd=3)
library(ggplot2)
set.seed(1000)
lambda <- 0.2
theo_mean <- 1/lambda #which the result is 5
theo_var <- 1/(lambda^2)/n
iteration <- 10000
n <- 40
exp_distrib <- rexp(n, lambda)
length(exp_distrib)
exp_distrib2 <- replicate(iteration,rexp(n, lambda))
dim (exp_distrib2)
hist(exp_distrib2, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17), xlim = c(0,40))
lines(density(exp_distrib2), col = c('#FF6666'), lwd=3)
colmean <- colMeans(exp_distrib2)
sample_mean <- mean(colmean)
sample_var <- var(colmean)
print(paste("Theorical mean equal to", theo_mean, "and sample mean equal to",round(sample_mean,3)))
print(paste("Theorical variance equal to", theo_var, "and sample variance equal to",round(sample_var,3)))
cumul_mean <-cumsum(colmean)/seq_along(colmean)
cumum_var <- cumsum(var(colmean))
plot(cumul_mean, type="l", col = c('#663300'), lwd =2 ,xlab = "Iterations", ylab = "Mean value", main = expression("Cumulative Emperical Mean " (lambda *" = 0.2")))
abline(h=theo_mean, col = c('#FF6666'), lwd=2)
hist(colmean, breaks = 20, freq = FALSE, xlim = c(2,9), ylim = c(0,0.6),col = c('#99CCFF'), main = "Mean distribution : almost Normal", xlab = "Mean")
hist(colmean, breaks = 25, freq = FALSE, xlim = c(2,9), ylim = c(0,0.6),col = c('#99CCFF'), main = "Mean distribution : almost Normal", xlab = "Mean")
lines(density(colmean), col = c('#FF6666'), lwd=3)
abline(v=sample_mean, col = c('#FF66FF'), lwd=3)
legend("topright", legend = c("Mean"), col = c('#FF66FF'), lwd =2)
a <- set.seed(1000)
a
hist(exp_distrib2, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17), xlim = c(0,40))
hist(exp_distrib2, breaks = 20, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17), xlim = c(0,40))
hist(exp_distrib2, breaks = 25, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17), xlim = c(0,40))
lines(density(exp_distrib2), col = c('#FF6666'), lwd=3)
n <- 400
exp_distrib <- rexp(n, lambda)
length(exp_distrib)
exp_distrib2 <- replicate(iteration,rexp(n, lambda))
dim (exp_distrib2)
hist(exp_distrib2, breaks = 25, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17), xlim = c(0,40))
lines(density(exp_distrib2), col = c('#FF6666'), lwd=3)
n <- 40
exp_distrib <- rexp(n, lambda)
length(exp_distrib)
exp_distrib2 <- replicate(iteration,rexp(n, lambda))
dim (exp_distrib2)
hist(exp_distrib2, breaks = 25, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17), xlim = c(0,40))
lines(density(exp_distrib2), col = c('#FF6666'), lwd=3)
cumexp <- cumsum(exp_distrib2)/seq_along(exp_distrib2)
hist(cumexp, breaks = 25, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17), xlim = c(0,40))
hist(cumexp, breaks = 25, col = c('#99CCFF'), xlab ="X", main = expression("Exponential distribution "(lambda *" = 0.2")), freq = FALSE , ylim = c(0,0.17))
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
summary(fit)$coefficients[2,4]
summary(fit)
summary(fit)$sigma
data(mtcars)
fit <- lm(mpg ~ wt, data=mtcars)
(summary(fit)$coeff)
(summary(fit)$coeff)
predict(fit, newdata, interval=("confidence"))
newdata <- data.frame(wt=mean(mtcars$wt))
predict(fit, newdata, interval=("confidence"))
?mtcars
requite(datasets)
require(datasets)
data("swiss")
data("swiss)
data("swiss)
data(swiss)
require(GGally)
require(ggplot2)
ggpairs(swiss, lower = list(continuous = "smooth"), params = c(method = "loess"))
ggpairs(swiss, lower = list(continuous = "smooth"))
install_from_swirl("Regression Models")
package_version("swirl")
library(swirl)
install_from_swirl("Regression Models")
swirl()
plot(child~parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child~parent, galton)
abline(regrline, lwd = 3, col ="red")
summary(regrline)
lm(child~parent,galton)
fit <- lm(child~parent,galton)
summary(fiti)
summary(fit)
fit$residuals
mean(fit$residuals)
cov(fit$residuals,galto$parent)
cov(fit$residuals,galton$parent)
v
fit$coef[1]
ols.ic <- fit$coef[1]
ols.slope <- fit$coefficients[2]
ols.slope <- fit$coef[2]
rhd - lhs
Here are the vectors of variations or tweaks
sltweak <- c(.01, .02, .03, -.01, -.02, -.03) #one for the slope
ictweak <- c(.1, .2, .3, -.1, -.2, -.3)  #one for the intercept
lhs <- numeric()
rhs <- numeric()
#left side of eqn is the sum of squares of residuals of the tweaked regression line
for (n in 1:6) lhs[n] <- sqe(ols.slope+sltweak[n],ols.ic+ictweak[n])
#right side of eqn is the sum of squares of original residuals + sum of squares of two tweaks
for (n in 1:6) rhs[n] <- sqe(ols.slope,ols.ic) + sum(est(sltweak[n],ictweak[n])^2)
lhs - rhs
all.equal(lhs,rhs)
``
à
à
0
0
info()
bye()
install.packages("kernlab")
data(kernlab)
data("kernlab")
data(spam)
library(kernlab)
data(spam)
View(spam)
library(caret)
install.packages("caret")
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
data(AlzheimerDisease)
View(predictors)
adData = data.frame(diagnosis,predictors)
View(adData)
diagnosis
inTrain = createDataPartition(adData$diagnosis, p = 3/4)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)
inTrain
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
inTrain
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
View(training)
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
t<-training[, IL_col_idx]
View(t)
preObj <- preProcess(t, method=c("center", "scale", "pca"), thresh=0.9)
preObj
preObj <- preProcess(t, method=c("center", "scale", "pca"), thresh=0.8)
preObj
names(preObj)
new_testing <- testing[, c(names(testing)[IL_col_idx], "diagnosis")]
View(testing)
View(new_testing)
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
install.packages("e1071")
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
non_pca_model
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log(training$Superplasticizer+1))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
suppressMessages(library(caret))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
suppressMessages(library(caret))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE)
View(segmentationOriginal)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
install.packages("rpart")
install.packages("rpart")
library(rpart)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit
modFit$finalModel
library(rattle)
install.packages("rattle")
install.packages("rpart.plot")
library(rattle)
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,
data = training,
method = "rpart")
model<-train(Class ~ .,data = training,  method = "rpart")
model<-train(Class ~ .,data = training,  method = "rpart")
fancyRpartPlot(model$finalModel)
mdata.bank <- read.csv("./banks.csv")
setwd("~/DataScience/Projet/bank_failures/Bank_failure")
mdata.bank <- read.csv("./banks.csv")
table(mdata.bank$Institution.Type)
institution <<- list("COMMERCIAL BANK","SAVINGS ASSOCIATIONS","SAVINGS BANK")
mdata.bank$Failure.Date <- as.Date(mdata.bank$Failure.Date, "%m/%d/%Y")
mdata.bank$Estimated.Loss..2015.[is.na(mdata.bank$Estimated.Loss..2015.)] <- 0
mdata.work <- mdata.bank  %>% select(Institution.Name,Institution.Type,Failure.Date,Estimated.Loss..2015.)
colname <- c("Name","Type", "Date", "Loss")
names(mdata.work) <- colname
mdata.work$Date <- format(mdata.work$Date, "%Y")
mdata.work <- mdata.work %>% group_by(Date,Type,Name) %>%  summarise(Loss = sum(Loss))
mdata.work$Date <- as.numeric(mdata.work$Date)
mdata.work$Loss <- mdata.work$Loss/1000000
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(plotly)
mdata.work <- mdata.bank  %>% select(Institution.Name,Institution.Type,Failure.Date,Estimated.Loss..2015.)
colname <- c("Name","Type", "Date", "Loss")
names(mdata.work) <- colname
mdata.work$Date <- format(mdata.work$Date, "%Y")
mdata.work <- mdata.work %>% group_by(Date,Type,Name) %>%  summarise(Loss = sum(Loss))
mdata.work$Date <- as.numeric(mdata.work$Date)
mdata.work$Loss <- mdata.work$Loss/1000000
mdata.work2 <- mdata.work %>% filter(Type == "COMMERCIAL BANK") %>% arrange(desc(Loss))
mdata.work2 <- head(mdata.work2,5)
ggplot(mdata.work, aes(Date,Loss, fill=Type)) +
geom_bar(stat = "identity") +
scale_fill_brewer(palette="Pastel2") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
xlim(1980,2020) +
ylab("Loss (in billion)") +
ggtitle("A History of Bank losses in the United States since 1986")
mdata.work1 <- mdata.work %>% filter(Type == institution)
institution <<- c("COMMERCIAL BANK","SAVINGS ASSOCIATIONS","SAVINGS BANK")
mdata.work1 <- mdata.work %>% filter(Type == institution)
institutions <<- c("COMMERCIAL BANK","SAVINGS ASSOCIATIONS","SAVINGS BANK")
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(plotly)
institutions <<- list("COMMERCIAL BANK","SAVINGS ASSOCIATIONS","SAVINGS BANK")
getpart1 <- function(institution) {
if (!(institution %in% institutions))
stop("Unknown institution")
mdata.bank <- read.csv("./banks.csv")
mdata.bank$Failure.Date <- as.Date(mdata.bank$Failure.Date, "%m/%d/%Y")
mdata.bank$Estimated.Loss..2015.[is.na(mdata.bank$Estimated.Loss..2015.)] <- 0
mdata.work <- mdata.bank  %>% select(Institution.Name,Institution.Type,Failure.Date,Estimated.Loss..2015.)
colname <- c("Name","Type", "Date", "Loss")
names(mdata.work) <- colname
mdata.work$Date <- format(mdata.work$Date, "%Y")
mdata.work <- mdata.work %>% group_by(Date,Type,Name) %>%  summarise(Loss = sum(Loss))
mdata.work$Date <- as.numeric(mdata.work$Date)
mdata.work$Loss <- mdata.work$Loss/1000000
mdata.work1 <- mdata.work %>% filter(Type == institution)
}
shiny::runApp()
runApp()
runApp()
runApp()
setwd("~/DataScience/Projet/bank_failures")
mdata.bank <- fread('data/banks.cvs')
install.packages("data.table")
library(data.table)
runApp()
library(data.table)
mdata.bank <- fread('data/banks.cvs')
setwd("~/DataScience/Projet/bank_failures")
mdata.bank <- fread('data/banks.cvs')
mdata.bank <- fread('data/banks.csv')
View(mdata.bank)
mdata.bank$Failure.Date <- as.Date(mdata.bank$Failure.Date, "%m/%d/%Y")
mdata.bank$Estimated.Loss..2015.[is.na(mdata.bank$Estimated.Loss..2015.)] <- 0
mdata.work <- mdata.bank  %>% select(Institution.Name,Institution.Type,Failure.Date,Estimated.Loss..2015.)
colname <- c("Name","Type", "Date", "Loss")
names(mdata.work) <- colname
mdata.work$Date <- format(mdata.work$Date, "%Y")
mdata.work <- mdata.work %>% group_by(Date,Type,Name) %>%  summarise(Loss = sum(Loss))
mdata.work$Date <- as.numeric(mdata.work$Date)
mdata.work$Loss <- mdata.work$Loss/1000000
mdata.work1 <- mdata.work %>% filter(Type == institution)
library(dplyr)
mdata.bank$Failure.Date <- as.Date(mdata.bank$Failure.Date, "%m/%d/%Y")
mdata.bank$Estimated.Loss..2015.[is.na(mdata.bank$Estimated.Loss..2015.)] <- 0
mdata.work <- mdata.bank  %>% select(Institution.Name,Institution.Type,Failure.Date,Estimated.Loss..2015.)
colname <- c("Name","Type", "Date", "Loss")
names(mdata.work) <- colname
mdata.work$Date <- format(mdata.work$Date, "%Y")
mdata.work <- mdata.work %>% group_by(Date,Type,Name) %>%  summarise(Loss = sum(Loss))
mdata.work$Date <- as.numeric(mdata.work$Date)
mdata.work$Loss <- mdata.work$Loss/1000000
mdata.work1 <- mdata.work %>% filter(Type == institution)
mdata.bank$Failure.Date <- as.Date(mdata.bank$Failure.Date, "%m/%d/%Y")
mdata.bank$Estimated.Loss..2015.[is.na(mdata.bank$Estimated.Loss..2015.)] <- 0
mdata.work <- mdata.bank  %>% select(Institution.Name,Institution.Type,Failure.Date,Estimated.Loss..2015.)
colname <- c("Name","Type", "Date", "Loss")
names(mdata.work) <- colname
mdata.work$Date <- format(mdata.work$Date, "%Y")
mdata.work <- mdata.work %>% group_by(Date,Type,Name) %>%  summarise(Loss = sum(Loss))
mdata.work$Date <- as.numeric(mdata.work$Date)
mdata.work$Loss <- mdata.work$Loss/1000000
View(mdata.bank)
mdata.work <- mdata.bank  %>% select(Institution.Name,Institution.Type,Failure.Date,Estimated.Loss..2015.)
View(mdata.bank)
mdata.bank$`Failure Date`
mdata.bank <- fread('data/banks.csv')
mdata.bank$`Failure Date` <- as.Date(mdata.bank$`Failure Date`, "%m/%d/%Y")
View(mdata.bank)
mdata.bank$`Estimated Loss (2015)`[mdata.bank$`Estimated Loss (2015)`] <- 0
mdata.bank$`Estimated Loss (2015)`[is.na(mdata.bank$`Estimated Loss (2015)`)] <- 0
mdata.work <- mdata.bank  %>% select(`Institution Name`,`Institution Type`,`Failure Date`,`Estimated Loss (2015)`)
View(mdata.work)
colname <- c("Name","Type", "Date", "Loss")
names(mdata.work) <- colname
mdata.work$Date <- format(mdata.work$Date, "%Y")
mdata.work <- mdata.work %>% group_by(Date,Type,Name) %>%  summarise(Loss = sum(Loss))
mdata.work$Date <- as.numeric(mdata.work$Date)
mdata.work$Loss <- mdata.work$Loss/1000000
runApp()
runApp()
runApp()
runApp()
dt <- fread('events.agg.csv')
View(dt)
dt$EVTYPE <- tolower(dt$EVTYPE)
evtypes <<- sort(unique(dt$EVTYPE))
runApp()
runApp()
runApp()
runApp()
runApp()
mdata.bank <- fread('data/banks.csv')
View(mdata.bank)
runApp()
runApp()
runApp()
View(mdata.bank)
ggplot(mdata.bank, aes(mdata.bank$`Institution Name`,mdata.bank$`Estimated Loss (2015)` , fill = mdata.bank$`Institution Name`)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank()) +
ylab("Loss (in billion)") +
xlab("Bank name")+
ggtitle("Top 5 - Commercial bank failure cost for federal government since 1986")
mdata.bank$`Failure Date` <- as.Date(mdata.bank$`Failure Date`, "%m/%d/%Y")
mdata.bank$`Estimated Loss (2015)`[is.na(mdata.bank$`Estimated Loss (2015)`)] <- 0
mdata.work <- mdata.bank  %>% select(`Institution Name`,`Institution Type`,`Failure Date`,`Estimated Loss (2015)`)
colname <- c("Name","Type", "Date", "Loss")
names(mdata.work) <- colname
mdata.work$Date <- format(mdata.work$Date, "%Y")
mdata.work <- mdata.work %>% group_by(Date,Type,Name) %>%  summarise(Loss = sum(Loss))
mdata.work$Date <- as.numeric(mdata.work$Date)
mdata.work$Loss <- mdata.work$Loss/1000000
View(mdata.work)
ggplot(mdata.work, aes(Name,Loss , fill = Name)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank()) +
ylab("Loss (in billion)") +
xlab("Bank name")+
ggtitle("Top 5 - Commercial bank failure cost for federal government since 1986")
